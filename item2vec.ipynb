{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.item2vec_recommender_utils import hit_rate_evaluate, recommend, get_similar_artists\n",
    "from utils.metrics import MAPk, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = pd.read_pickle('data/train_grouped.pickle')\n",
    "test_grouped = pd.read_pickle('data/test_grouped.pickle')\n",
    "left_out_df = pd.read_pickle('data/left_out_df.pickle')\n",
    "train_lo = pd.read_pickle('data/train_lo_grouped.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>persons_lst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[383681, 42218, 307555, 211023, 104136, 104136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[4052, 286091, 120527, 176110, 51868, 35695, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[191173, 283933, 336778, 345237, 147566, 48766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[19627, 19627, 19627, 19627, 19627, 306470, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[238498, 295341, 271682, 172564, 390585, 14952...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                        persons_lst\n",
       "0        1  [383681, 42218, 307555, 211023, 104136, 104136...\n",
       "1        3  [4052, 286091, 120527, 176110, 51868, 35695, 2...\n",
       "2        4  [191173, 283933, 336778, 345237, 147566, 48766...\n",
       "3        5  [19627, 19627, 19627, 19627, 19627, 306470, 24...\n",
       "4        7  [238498, 295341, 271682, 172564, 390585, 14952..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2208857</th>\n",
       "      <td>25817</td>\n",
       "      <td>20735</td>\n",
       "      <td>1392140023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13120825</th>\n",
       "      <td>39916</td>\n",
       "      <td>382213</td>\n",
       "      <td>1411980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19207096</th>\n",
       "      <td>19575</td>\n",
       "      <td>309884</td>\n",
       "      <td>1396261680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764280</th>\n",
       "      <td>4501</td>\n",
       "      <td>272420</td>\n",
       "      <td>1409545293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27871472</th>\n",
       "      <td>1463</td>\n",
       "      <td>385249</td>\n",
       "      <td>1418905945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id person_id          ts\n",
       "2208857     25817     20735  1392140023\n",
       "13120825    39916    382213  1411980800\n",
       "19207096    19575    309884  1396261680\n",
       "764280       4501    272420  1409545293\n",
       "27871472     1463    385249  1418905945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = list(train_grouped['persons_lst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare artists names and left-out set dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = pd.read_pickle('data/new_persons_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>person_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145148</td>\n",
       "      <td>Everything+Is+Illuminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297899</td>\n",
       "      <td>Robin+O%27Brien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250429</td>\n",
       "      <td>Nicholas+Gunn++(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32765</td>\n",
       "      <td>Aspasia+Stratigou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18689</td>\n",
       "      <td>Allison+Veltz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560922</th>\n",
       "      <td>544215</td>\n",
       "      <td>Sanaa+Kariakoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560923</th>\n",
       "      <td>298403</td>\n",
       "      <td>Rock-a-teens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560924</th>\n",
       "      <td>450896</td>\n",
       "      <td>Jennifer+Lopez+Ft.+DJ+Mustard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560925</th>\n",
       "      <td>53831</td>\n",
       "      <td>Bobby+Sanabria+Conducting+The+Manhattan+School...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560926</th>\n",
       "      <td>526710</td>\n",
       "      <td>Montserrat+Figueras,+Jordi+Savall,+Arianna+Sav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560927 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        person_id                                        person_name\n",
       "0          145148                          Everything+Is+Illuminated\n",
       "1          297899                                    Robin+O%27Brien\n",
       "2          250429                              Nicholas+Gunn++(2012)\n",
       "3           32765                                  Aspasia+Stratigou\n",
       "4           18689                                      Allison+Veltz\n",
       "...           ...                                                ...\n",
       "560922     544215                                     Sanaa+Kariakoo\n",
       "560923     298403                                       Rock-a-teens\n",
       "560924     450896                      Jennifer+Lopez+Ft.+DJ+Mustard\n",
       "560925      53831  Bobby+Sanabria+Conducting+The+Manhattan+School...\n",
       "560926     526710  Montserrat+Figueras,+Jordi+Savall,+Arianna+Sav...\n",
       "\n",
       "[560927 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df['person_id'] = people_df['person_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560927"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(people_df['person_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dict = pd.Series(people_df['person_name'].values, index=people_df['person_id']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ariana+Grande'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_dict['29692']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_out_dict = pd.Series(left_out_df['person_id'].values, index=left_out_df['user_id']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train word2vec embeddings with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the word2vec model training and hit rate evaluation takes time, I decided to train several models with different parameters manually (make manual hyperparameter tuning) and choose the best one. But if I had more computational power and time, I would automate this process (for example, using GridSearch or a custom algorithm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 43s, sys: 1.79 s, total: 45min 45s\n",
      "Wall time: 15min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1 = Word2Vec(size = 50, window = 10, sg = 1, hs = 0, min_count=1)\n",
    "\n",
    "model1.build_vocab(train_lst, progress_per=200)\n",
    "\n",
    "model1.train(train_lst, total_examples = model1.corpus_count, \n",
    "            epochs=5, report_delay=1)\n",
    "model1.save('item2vec_savings/item2vec_s50_w10_5ep.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 49min 56s, sys: 1.84 s, total: 1h 49min 58s\n",
      "Wall time: 36min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = Word2Vec(size = 50, window = 30, sg = 1, hs = 0, min_count=1)\n",
    "\n",
    "model2.build_vocab(train_lst, progress_per=200)\n",
    "\n",
    "model2.train(train_lst, total_examples = model2.corpus_count, \n",
    "            epochs=5, report_delay=1)\n",
    "model2.save('item2vec_savings/item2vec_s50_w30_5ep.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 11s, sys: 1.41 s, total: 50min 13s\n",
      "Wall time: 16min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model3 = Word2Vec(size = 100, window = 10, sg = 1, hs = 0, min_count=1)\n",
    "\n",
    "model3.build_vocab(train_lst, progress_per=200)\n",
    "\n",
    "model3.train(train_lst, total_examples = model3.corpus_count, \n",
    "            epochs=5, report_delay=1)\n",
    "model3.save('item2vec_savings/item2vec_s100_w10_5ep.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 37s, sys: 1.7 s, total: 26min 38s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model4 = Word2Vec(size = 50, window = 5, sg = 1, hs = 0, min_count=1)\n",
    "\n",
    "model4.build_vocab(train_lst, progress_per=200)\n",
    "\n",
    "model4.train(train_lst, total_examples = model4.corpus_count, \n",
    "            epochs=5, report_delay=1)\n",
    "model4.save('item2vec_savings/item2vec_s50_w5_5ep.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec.load('item2vec_savings/item2vec_s50_w10_5ep.sav')\n",
    "model2 = Word2Vec.load('item2vec_savings/item2vec_s50_w30_5ep.sav')\n",
    "model3 = Word2Vec.load('item2vec_savings/item2vec_s100_w10_5ep.sav')\n",
    "model4 = Word2Vec.load('item2vec_savings/item2vec_s50_w5_5ep.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=515265, size=50, alpha=0.025)\n",
      "Word2Vec(vocab=515265, size=50, alpha=0.025)\n",
      "Word2Vec(vocab=515265, size=100, alpha=0.025)\n",
      "Word2Vec(vocab=515265, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)\n",
    "print(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hit rate evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claculate hit rate using left-one-out data in order to decide which model is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations calculated\n",
      "Starting hit rate calculation\n",
      "CPU times: user 47min 1s, sys: 1.7 s, total: 47min 2s\n",
      "Wall time: 12min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_rate1 = hit_rate_evaluate(model1, train_lo, left_out_dict, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations calculated\n",
      "Starting hit rate calculation\n",
      "CPU times: user 38min 38s, sys: 572 ms, total: 38min 38s\n",
      "Wall time: 9min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_rate2 = hit_rate_evaluate(model2, train_lo, left_out_dict, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations calculated\n",
      "Starting hit rate calculation\n",
      "CPU times: user 53min 46s, sys: 823 ms, total: 53min 47s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_rate3 = hit_rate_evaluate(model3, train_lo, left_out_dict, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations calculated\n",
      "Starting hit rate calculation\n",
      "CPU times: user 39min 27s, sys: 776 ms, total: 39min 28s\n",
      "Wall time: 10min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_rate4 = hit_rate_evaluate(model4, train_lo, left_out_dict, people_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034893381334810303\n",
      "0.005234007200221546\n",
      "0.0022431459429520908\n",
      "0.004707837164220438\n"
     ]
    }
   ],
   "source": [
    "print(hit_rate1)\n",
    "print(hit_rate2)\n",
    "print(hit_rate3)\n",
    "print(hit_rate4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model2 gave the best hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=515265, size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make recommendations for test set and calculate MAPk, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 12s, sys: 1.66 s, total: 12min 14s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_20_names, top_20_ids = recommend(model2, test_grouped, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_grouped['persons_lst']\n",
    "y_pred = top_20_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk_scores = []\n",
    "\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    mapk_scores.append(MAPk(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03134228564094112"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mapk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = []\n",
    "\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    prec.append(precision(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018057553956834532"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = []\n",
    "\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    rec.append(recall(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053591719382843475"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make the same for the second best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 15s, sys: 523 ms, total: 12min 16s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_20_names2, top_20_ids2 = recommend(model4, test_grouped, people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2 = test_grouped['persons_lst']\n",
    "y_pred2 = top_20_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk_scores2 = []\n",
    "\n",
    "for t, p in zip(y_true2, y_pred2):\n",
    "    mapk_scores2.append(MAPk(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043636070223545265"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mapk_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec2 = []\n",
    "\n",
    "for t, p in zip(y_true2, y_pred2):\n",
    "    prec2.append(precision(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032302158273381294"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = []\n",
    "\n",
    "for t, p in zip(y_true2, y_pred2):\n",
    "    rec2.append(recall(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07597972239961429"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPk, recall and precision are better for the second best by hit rate model (model4). I decided to use model4 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {'mapk': mapk_scores2,\n",
    "               'precision': prec2,\n",
    "               'recall': rec2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"item2vec_savings/scores_dict.pkl\", \"wb\")\n",
    "pickle.dump(scores_dict, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. List top-20 most similar artists for some artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ariana+Grande'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pop singer\n",
    "people_dict['29692']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Becky+G', 0.9078719019889832),\n",
       " ('Meghan+Trainor', 0.9060198664665222),\n",
       " ('Jessie+J.', 0.9058918952941895),\n",
       " ('Fifth+Harmony', 0.9012002944946289),\n",
       " ('%C2%8Bk%C2%8Cc%C2%91%C2%BE', 0.8878846168518066),\n",
       " ('Iggy+Azalea+ft.+Charli+XCX', 0.8873310685157776),\n",
       " ('Sigma.', 0.8866012692451477),\n",
       " ('G.R.L.', 0.8837899565696716),\n",
       " ('Iggy+Azalea+(Featuing+M%C3%98)', 0.8813971281051636),\n",
       " ('Magic!+&+Zedd', 0.8811827898025513),\n",
       " ('Clean+Bandit+f%2FJess+Glynne', 0.8790188431739807),\n",
       " ('Born+This+Way', 0.8757053017616272),\n",
       " ('Jessie+J,+Ariana+Grande+&+Nicki+Minaj', 0.8739939332008362),\n",
       " ('Jessie+J+ft.+Ariana+Grande+&+Nick+Minaj', 0.873116135597229),\n",
       " ('Mr.+Probz,+Robin+Schulz', 0.871794581413269),\n",
       " ('Matisyahu,+Richello', 0.8713920712471008),\n",
       " ('Beyonc%C3%A9+ft.+Chimamanda+Ngozi+Adiche', 0.8678398728370667),\n",
       " ('Olly+Murs+feat.+Aliz%C3%A9e', 0.8677894473075867),\n",
       " ('Nicki+Minaj+vs+Gretchen+feat.+Garotas+da+Laje', 0.8674243688583374),\n",
       " ('Jessie+J+feat.+Ariana+Grande+&+Nicki+Minaj', 0.8665834069252014)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, ids = get_similar_artists(model4, model4['29692'], people_dict)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Freddie+Mercury'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rock \n",
    "people_dict['157384']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Queen+&+The+Muppets', 0.8720742464065552),\n",
       " ('George+Michael+and+Queen', 0.8444976806640625),\n",
       " ('The+Cross', 0.8327374458312988),\n",
       " ('A+Caverna', 0.8240128755569458),\n",
       " ('Queen+%252B+Wyclef+Jean', 0.8156170845031738),\n",
       " ('Aerosmith', 0.8089699745178223),\n",
       " ('Kimnowak', 0.8084118366241455),\n",
       " ('Queen+%252B+Elton+John', 0.803917407989502),\n",
       " ('Vladimir+Vysotsky,+Melodia+&+G.+Garanyan', 0.799826979637146),\n",
       " ('Uriah+Heep', 0.7972726225852966),\n",
       " ('Amanda+Plummer', 0.7937545776367188),\n",
       " ('Tia+Carrere', 0.7937341332435608),\n",
       " ('Kennedy+Center+Honors+2012', 0.7930720448493958),\n",
       " ('Freddie+Mercury+%252B+Monserrat+Caball%C3%A9', 0.7897298336029053),\n",
       " ('Duran+Duran', 0.7892658710479736),\n",
       " ('Lenny+Kravitzz', 0.7886962294578552),\n",
       " ('Whitesnake', 0.7855861186981201),\n",
       " ('Jim+Horn', 0.7854337692260742),\n",
       " ('6.+Jay+Timberly', 0.7841383218765259),\n",
       " ('Def+Leopard', 0.783647894859314)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, ids = get_similar_artists(model4, model4['157384'], people_dict)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mac+Miller+feat.+Action+Bronson'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rap\n",
    "people_dict['211094']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mac+Miller%2FEarl+Sweatshirt%2FVinny+Radio', 0.9166097640991211),\n",
       " ('A$AP+Ferg+featuring+A$AP+Rocky,+French+Montana,+Trinidad+James+&+Schoolboy+Q',\n",
       "  0.886242151260376),\n",
       " ('Black+Hippy', 0.8783423900604248),\n",
       " ('3-6+Mafia%7CTrillville%7CLord+Infamous%7CProject+Pat', 0.8768203258514404),\n",
       " ('MellowHype', 0.875748336315155),\n",
       " ('Ace+Hood%2FFuture%2FRick+Ross', 0.8739904761314392),\n",
       " ('Kid+Cudi+vs+Crookers', 0.8737793564796448),\n",
       " ('Kid+Cudi%2FKing+Chip%2FA$AP+Rocky', 0.8727040886878967),\n",
       " ('A$AP+Ferg+feat.+Shabba+Ranks,+Busta+Rhymes+&+Migos', 0.8694416284561157),\n",
       " ('MellowHigh+feat.+Earl+Sweatshirt+and+Remy+Banks', 0.8684039115905762),\n",
       " ('Pusha+T', 0.8651683926582336),\n",
       " ('Oskar+Koch', 0.8645967245101929),\n",
       " ('Earl+Sweatshirt,+Matthew+Tavares,+Alex+Sowinski+&+Chester+Handsen',\n",
       "  0.8623257875442505),\n",
       " ('Schoolboy+Q.', 0.8622783422470093),\n",
       " ('Franchise', 0.8619042634963989),\n",
       " ('Taj-He-Spitz', 0.8605881929397583),\n",
       " ('Kendrick+Lamar%2FBJ', 0.8603178858757019),\n",
       " ('Asher+Roth', 0.8582335710525513),\n",
       " ('J+Cole%2FAmber+Coffman', 0.8578799366950989),\n",
       " ('Kanye+West,+Big+Sean,+Pusha+T+&+2+Chainz', 0.8557713627815247)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, ids = get_similar_artists(model4, model4['211094'], people_dict)\n",
    "names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
